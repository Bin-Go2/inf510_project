{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INF 510 Fall 2019 Final Project Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t**The names of team member(s)**:\n",
    "\n",
    "    Bin Zhang\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\t**How to run your code (what command-line switches they are, what happens when you invoke the code, etc.)**\n",
    "\n",
    "    This project requires the following packages:\n",
    "    - django、requests、beautifulsoup4、retry、selenium、lxml、tqdm\n",
    "    \n",
    "    To run this project, make sure the above packages are installed, and then simply clone the repo at https://github.com/SondersB/inf510_project/ and execute this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\t**Any major “gotchas” to the code (i.e. things that don’t work, go slowly, could be improved, etc.)**\n",
    "    \n",
    "    Before starting the jupyter notebook, it needs to navaigate this project at first, Otherwise the follwing command will not be run successfully.<br>\n",
    "    The code nests the django project commands, so it needs to manully interupt the cell after start the web server. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  **Anything else you feel is relevant to the grading of your project your project.**\n",
    "\n",
    "    For some reason, if you go the webpages http://127.0.0.1:8000/all_flights/ and move the mouse to each province, it will display the name and the latitude of this province, however when you inspect the html and look at the Console, I did transfer all the data and I don't know why it just shows 2 records.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **What did you set out to study?  (i.e. what was the point of your project?  This should be close to your Milestone 1 assignment, but if you switched gears or changed things, note it here.)**\n",
    "\n",
    "   My aims is to anlayze the relationship among city's GDP and population and its flight number. And if possible, I will acheive a ticket booking system to achieve a user login/sign up、ticket booking、ticket refunding modules to collect user's purchasing information and dive into the relationship among each of these varibles. Whereas I just accompished the login/sign up module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What did you Discover/what were your conclusions (i.e. what were your findings?  Were your original assumptions confirmed, etc.?)**\n",
    "\n",
    "   When you look at the http://127.0.0.1:8000/statistic/, the correlation calculation shows<br>\n",
    "   (1) GDP rank has a strong negative relationship with flight numbers --- larger GPD , less flight numbers<br>\n",
    "   (2) GDP rank has a mild negative relationship with population --- large GPD , less population<br>\n",
    "   (3) Population has a medium positive relationship with flight numbers ---- more people, more flights (which I think it's reasonable)\n",
    "   \n",
    "   My original thought is that more pepole will result in more fight numbers and GDP ranking while the number shows only more poeple leads to more flights and the relationship between GDP and flights, the relationship between GDP and population are negative correalation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **What difficulties did you have in completing the project?**  \n",
    "    From the project, I realize that the most diffcult part is scraping ---- collecting data. I nearly spent a whole week to fulfill the scraping part beacuse all the filght websites have a strong anti-scarping strategy. I can't use requests library to access these information directly. And during this period, I stimulated the cookie, header, analyzed js. But finally I decided to use selenium to atumoated scrape the information like users. It sepnd a lot of time waiting for the searching and stroing. <br>\n",
    "    And when it comes to the visualization and analysis part,the problem for is how to display the result. And I heard Django was a good framework to illustrate information as htmls. So I learned it and find it's pretty easy to build a lightweight website via Django. But there are still troubles when I use it. The first thing is displaying. What I know is just simple html、css languages. They can't display so well. So I searched the Internet and used a framework called bootstrap to help me. Another thing is front-end interaction, even though I can use SQL to get the information I want, I don't know how to transfer it to the front end. After several trials, I know how to use 'context' (a django term) to transfer my data and changing its encoing foramt to make it compatible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **What skills did you wish you had while you were doing the project?**\n",
    "   * Significant improvement in crawler skills (selenium、beautifulsoup、requests、xpath)\n",
    "   * Become more proficient in database language operations\n",
    "   * Know how to use Django to build a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **What would you do “next” to expand or augment the project?**\n",
    "\n",
    "    Actually, I don't have much time to make my project more colorful. So I don't achieve the tickt booking system. Maybe after that I will fulfill the booking module and refunding module to enhance the user interation rather than just showing the results. Besides, in this project, the UI is not so good and I didn't make it flexible, so it will display well in the Mac 15-inch screen. But in other screen, because of the size design, it will not be compative and display bad. After that I will make it more flexible. Another thing is the database design, here I don't consider it too much and for the sake of reduing searching time, I used some spacing redundancy. After that I can redegin it and make it more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhangbin/Desktop/inf510_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we navigate to the Django project to make sure current directory has the file manage.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangbin/Desktop/inf510_project/FlightInfo\n"
     ]
    }
   ],
   "source": [
    "cd FlightInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight.db  \u001b[1m\u001b[36mFlightInfo\u001b[m\u001b[m \u001b[1m\u001b[36mairlines\u001b[m\u001b[m   \u001b[31mmanage.py\u001b[m\u001b[m  readme.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watching for file changes with StatReloader\n",
      "Performing system checks...\n",
      "\n",
      "System check identified no issues (0 silenced).\n",
      "December 11, 2019 - 23:27:24\n",
      "Django version 3.0, using settings 'FlightInfo.settings'\n",
      "Starting development server at http://127.0.0.1:8000/\n",
      "Quit the server with CONTROL-C.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python manage.py runserver #  run the web server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please manually interrupt the cell above to close the web server, otherwise we cannot run the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import datetime as dt\n",
    "np.random.seed(1) # For reproducibility\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make millions betting on the NBA, but to do that I have to know how much to bet on each game. Luckily, the Kelly Criterion can help me size my bets based on a known edge (that I don't have yet).\n",
    "\n",
    "But let's use a [biased] coin instead, and pretend I know I have a 5% edge, and use Kelly to see my optimal bet sizes, and potential bankroll acrual across a number of bet fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly demo\n",
    "# Coin flip variable set up for our biased coin\n",
    "# Probability of win (\"unfair\" coin/heads)\n",
    "p = 0.55 \n",
    "# f is the optimal bankroll bet fraction according to the Kelly criterion.\n",
    "f = p - (1-p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing our simulation of coin flips with variables\n",
    "I = 50 #The number of series to be simulated.\n",
    "n = 100 #The number of trials per series.\n",
    "\n",
    "def run_simulation(f):\n",
    "    c = np.zeros((n, I)) #Instantiates an ndarray object to store the simulation results.\n",
    "    c[0] = 100 #Initializes the starting capital with 100.\n",
    "    for i in range(I): #Outer loop for the series simulations.\n",
    "        for t in range(1,n): #Inner loop for the series itself.\n",
    "            o = np.random.binomial(1, p) #Simulates the tossing of a coin.\n",
    "            if o > 0: #If 1, i.e., heads …\n",
    "                c[t, i] = (1+f) * c[t-1,i] #… then add the win to the capital.\n",
    "            else: #If 0, i.e., tails …\n",
    "                c[t, i] = (1-f) * c[t-1,i] #… then subtract the loss from the capital.\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = run_simulation(f) # runs the simulation with f = .1 as per Kelly Criterion\n",
    "c_2 = run_simulation(0.05) #Simulation with f = 0.05.\n",
    "c_3 = run_simulation(0.25) #Simulation with f = 0.25.\n",
    "c_4 = run_simulation(0.5) #Simulation with f = 0.5.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(c_1.mean(axis=1), 'r', label='$f^*=0.1$')\n",
    "plt.plot(c_2.mean(axis=1), 'b', label='$f=0.05$')\n",
    "plt.plot(c_3.mean(axis=1), 'y', label='$f=0.25$')\n",
    "plt.plot(c_4.mean(axis=1), 'm', label='$f=0.5$')\n",
    "plt.legend(loc=0);\n",
    "plt.title('Varied KC Simulations of Rigged Coin Flips');\n",
    "plt.xlabel('Number of trials');\n",
    "plt.ylabel('$ Amount Won/Lost');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this a number of times, you'll see how a 50% bet size makes you go bust...even with such a biased coin!  That's nuts!\n",
    "\n",
    "But the Kelly Optimal bet size (10%) has a positive expected value, with much lower variance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, but I wanted to see if I could use offensive and defensive efficiency to project NBA games...are those metrics stable year over year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from nbastuffer.com; may differ from basketball-reference data\n",
    "# Read in the data\n",
    "\n",
    "# NOTE: This should be in the /data directory of my github repo!\n",
    "adv_df = pd.read_csv('nba_adv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the columns\n",
    "adv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns we want:\n",
    "adv_df[['TEAM', 'OEFF_2017', 'OEFF_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is offensive efficiency stable year over year?\n",
    "adv_df.set_index('TEAM').plot.scatter(x='OEFF_2017', y='OEFF_2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm.  Looks like there may be a linear relationship there.  A line would help..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the regression line in there\n",
    "sns.lmplot(x='OEFF_2017', y='OEFF_2018', data=adv_df, fit_reg=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm.  Still not convinced.  Let's look at $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at R^2\n",
    "adv_df[['OEFF_2017', 'OEFF_2018']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad!  So maybe offensive efficiency is predictive year over year!  But what if there are leaguewide trends we're not considering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "p1 = sns.scatterplot('OEFF_2017', # Horizontal axis\n",
    "       'OEFF_2018', # Vertical axis\n",
    "       data=adv_df, # Data source\n",
    "       size = 12,\n",
    "       legend=False)  \n",
    "\n",
    "for line in range(0,adv_df.shape[0]):\n",
    "     p1.text(adv_df.OEFF_2017[line]+0.01, adv_df.OEFF_2018[line], \n",
    "     f\"{adv_df.TEAM[line]}\\n({adv_df.OEFF_2018[line]-adv_df.OEFF_2017[line]:.2f})\", horizontalalignment='left', \n",
    "     size='14', color='black', weight='normal')\n",
    "\n",
    "X_plot = np.linspace(adv_df.OEFF_2017.min(), adv_df.OEFF_2017.max())\n",
    "Y_plot = np.linspace(adv_df.OEFF_2017.min(), adv_df.OEFF_2017.max())\n",
    "plt.plot(X_plot, Y_plot, color='r')\n",
    "        \n",
    "plt.title('Year-over-year NBA Offensive Efficiency (2018 Eff - 2017 Eff)', fontsize='18')\n",
    "# Set x-axis label\n",
    "plt.xlabel('2017 Offensive Efficiency', fontsize='18')\n",
    "# Set y-axis label\n",
    "plt.ylabel('2018 Offensive Efficiency', fontsize='18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!  It looks like the entire league is getting better offensively.  So maybe it's not that helpful?  If I was to continue this project, I'd want to see if efficiency metrics could be used to pick NBA winners via the Vegas moneyline.  I'd need daily lines data for this.  Then, I could use the optimal Kelly Betting strategy above to place optimal bet sizes based on my implied edge versus the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
